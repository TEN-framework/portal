---
title: NodeJS - Cascade Main
---

# Main Agent Extension for Node.js

The file [`index.ts`](./index.ts) defines the **MainControlExtension** — the entry point for Node.js agents in the TEN Framework.

This is the class that wires together **ASR results**, **LLM responses**, **tool registration**, and **interruption handling**.
If you’re building your own solution on top of TEN (with Node.js), start here.

---

## Quick File Layout

```
.
├── index.ts          → Main extension: message routing + interruption
├── helper.ts         → Utilities for sending Cmd/Data, sentence parsing
└── agent/
    ├── agent.ts      → Event bus + orchestration
    ├── events.ts     → Event classes (ASR, LLM, Tools, User)
    ├── llm_exec.ts   → LLM execution queue and handlers
    └── struct.ts     → Zod schemas for TTS/ASR/LLM messages
```

---

## Architecture Overview
<img src="https://ten-framework-assets.s3.amazonaws.com/blog/main-control/nine.svg" alt="Architecture" />

---

## The MainControlExtension (`index.ts`)

### Core Idea

* Extends `Extension` from `ten-runtime-nodejs`
* Normalizes runtime messages into **typed events** (`ASRResultEvent`, `LLMResponseEvent`, etc.)
* Routes events into the `Agent` class
* Manages **interruption** when users talk over the assistant

### Key Properties

```ts
class MainControlExtension extends Extension {
  tenEnv!: TenEnv;
  agent!: Agent;
  config!: MainControlConfig;

  joinedUserCount: number = 0;
  session_id: string = "0";
  turn_id: number = 0;
  sentenceFragment: string = "";
}
```

* `session_id` + `turn_id` track conversation state
* `sentenceFragment` accumulates partial output for sentence splitting

---

### ASR Event Handling

When ASR detects speech, it’s turned into an `ASRResultEvent`.

```ts
if (event.final || event.text.length > 2) {
  await this._interrupt(); // flush LLM/TTS if user is overlapping
}
if (event.final) {
  this.turn_id += 1;
  await this.agent.queueLLMInput(event.text);
}
await this._sendTranscript("user", event.text, event.final, Number(this.session_id));
```

* **Partial speech** → logged as transcript
* **Final speech** → queued for LLM input
* **Overlap** → `_interrupt()` cancels current LLM/TTS tasks

---

### LLM Response Handling

LLM responses are streamed sentence by sentence, then forwarded to TTS and transcript collectors.

```ts
if (!event.is_final && event.type === "message") {
  const [sentences, fragment] = parseSentences(this.sentenceFragment, event.delta);
  this.sentenceFragment = fragment;
  for (const s of sentences) {
    await this._sendToTTS(s, false);
  }
}

await this._sendTranscript(
  "assistant", event.text, event.is_final, 100,
  event.type === "reasoning" ? "reasoning" : "text"
);
```

* **Streaming** → TTS gets short sentences for natural speech
* **Final** → full transcript is sent and marked

---

### Tool Registration

The LLM can register tools dynamically.

```ts
async _onToolRegister(event: ToolRegisterEvent) {
  await this.agent.registerLLMTool(event.tool, event.source);
}
```

To extend: define your tool schema in `events.ts` and handle it in your `Agent` logic.

---

### Interruption Handling

Natural barge-in is handled by `_interrupt()`.

```ts
async _interrupt() {
  this.sentenceFragment = "";
  await this.agent.flushLLM();
  await sendData(this.tenEnv, "tts_flush", "tts", { flush_id: uuidv4() });
  await sendCmd(this.tenEnv, "flush", "agora_rtc");
}
```

* Flushes **LLM requests**
* Cancels **TTS playback**
* Signals RTC to stop streaming

This ensures the user can always cut in naturally.

---

## Supporting Components

* **`agent.ts`**: Manages event queues for ASR & LLM, plus handler registration
* **`llm_exec.ts`**: Async queue that sends requests to LLMs and handles streaming responses, aborts, and tool calls
* **`events.ts`**: Defines event classes like `ASRResultEvent`, `LLMResponseEvent`, `ToolRegisterEvent`
* **`helper.ts`**: Provides `sendCmd`, `sendData`, and `parseSentences` for splitting output into natural phrases    |

---

## How to Build Your Own Solution

* **Custom ASR flow** → edit `_onASRResult` to filter or preprocess speech
* **Custom LLM output** → change `_onLLMResponse` to modify text before TTS or UI
* **Add a tool** → extend `ToolRegisterEvent` and register in `Agent`
* **Tweak responsiveness** → adjust `_interrupt()` for stricter or looser barge-in handling

<Callout title="Node.js extension update">
  Changing files in Node.js extension requires a build step. Run `task build` to rebuild all Node.js extensions.
</Callout>

---

## Summary

* `index.ts` (`MainControlExtension`) is the **entry point** and **router**.
* It normalizes runtime messages into **typed events** and controls **interruption**.
* Supporting files (`agent/`, `helper.ts`) provide queues, event models, and execution helpers.

By following this structure, you can **quickly extend or replace** parts of the flow to build your own Node.js-based conversational agent on TEN.
